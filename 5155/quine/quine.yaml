apiVersion: apps/v1
kind: Deployment
metadata:
  name: quine
spec:
  replicas: 1
  selector:
    matchLabels:
      app: quine
  template:
    metadata:
      labels:
        app: quine
    spec:
      volumes:
        - name: config
          configMap:
            name: quine-config
      containers:
        - name: quine
          image: thatdot/quine:1.5.1
          ports:
            - containerPort: 8080
          env:
            - name: CASSANDRA_ENDPOINTS
              value: "cassandra.default.svc.cluster.local:9042"
            - name: CASSANDRA_USERNAME
              value: "cassandra"
            - name: CASSANDRA_PASSWORD
              value: "adminpassword"
          volumeMounts:
            - name: config
              mountPath: /quine
          command:
            [
              "sh",
              "-c",
              "#!sh \n java -Dconfig.file=/quine/quine.conf -jar quine-assembly-1.5.1.jar -r /quine/kafka-ingest.yaml --force-config",
            ]

---
apiVersion: v1
kind: Service
metadata:
  name: quine
spec:
  selector:
    app: quine
  ports:
    - name: default
      port: 8080
      targetPort: 8080

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: quine
spec:
  rules:
    - host: quine.test.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: quine
                port:
                  name: default

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: quine-config
data:
  kafka-ingest.yaml: |+
    version: 1
    title: Kafka Ingest
    contributor: https://github.com/landon9720
    summary: Ingest Kafka topic messages as graph nodes
    description: Ingests each message in the Kafka topic "quine" as a graph node
    ingestStreams:
      - type: KafkaIngest
        topics:
          - quine
        bootstrapServers: strimzi-kafka-kafka-bootstrap.svc.cluster.local:9092
        format:
          type: CypherJson
          query: |-
            MATCH (n)
            WHERE id(n) = idFrom($that)
            SET n = $that
    standingQueries:
      - pattern:
          type: Cypher
          query: MATCH (n) RETURN DISTINCT id(n) AS id
          mode: DistinctId
        outputs:
          toKafka:
            type: WriteToKafka
            topic: quine-output
            bootstrapServers: strimzi-kafka-kafka-bootstrap.svc.cluster.local:9092
            format:
              type: JSON
    nodeAppearances: [ ]
    quickQueries: [ ]
    sampleQueries: [ ]
  quine.conf: |+
    quine {
        dump-config = yes
        should-resume-ingest = yes

        store {
            # store data in an Apache Cassandra instance
            type = cassandra

            # "host:port" strings at which Cassandra nodes can be accessed from
            # the application
            endpoints = [
                ${CASSANDRA_ENDPOINTS}
            ]

            # the keyspace to use
            keyspace = quine

            # whether the application should create the keyspace if it does not
            # yet exist
            should-create-keyspace = false

            # whether the application should create tables in the keyspace if
            # they do not yet exist
            should-create-tables = true

            # how many copies of each datum the Cassandra cluster should retain
            replication-factor = 1

            # how many hosts must agree on a datum for Quine to consider that
            # datum written/read
            write-consistency = LOCAL_QUORUM
            read-consistency = LOCAL_QUORUM

            # passed through to Cassandra
            local-datacenter = "datacenter1"

            # how long to wait before considering a write operation failed
            write-timeout = "10s"

            # how long to wait before considering a read operation failed
            read-timeout = "10s"

            # if set, the number of nodes for which to optimize node creation
            # latency
            # bloom-filter-size =
        }
    }
    # configuration for which data to save about nodes and when to do so
    persistence {
        # whether to save node journals. "true" uses more disk space and
        # enables more functionality, such as historical queries
        journal-enabled = false

        # one of [on-node-sleep, on-node-update, never]. When to save a
        # snapshot of a node's current state, including any SingleId Standing
        # Queries registered on the node
        snapshot-schedule = on-node-sleep

        # whether only a single snapshot should be retained per-node. If false,
        # one snapshot will be saved at each timestamp against which a
        # historical query is made
        snapshot-singleton = true

        # when to save Standing Query partial result (only applies for the
        # `MultipleValues` mode -- `SingleId` Standing Queries always save when
        # a node saves a snapshot, regardless of this setting)
        standing-query-schedule = on-node-sleep
    }
    datastax-java-driver {
        advanced {
            auth-provider {
              class = PlainTextAuthProvider
              username = ${CASSANDRA_USERNAME}
              password = ${CASSANDRA_PASSWORD}
            }
        }
    }
